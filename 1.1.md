```python
import nltk
nltk.download()
from nltk.book import *
```
concordance: shows every occurence of a given word
```python
text1.concordance("monstrous")
```
similar: the other words that shows in a similar range of contexts
```python
text1.similar("monstrous")
```
common_contexts: examine the contexts that are shared by two or more words in documents
```python
text1.common_contexts(["monstrous","very"])
```
dispersion_plot:shows the location of aa word within the entire text
```python
text4.dispersion_plot(["citizens","democracy","freedom","duties","America","liberty"])
```
len(): the total tokens within a text
```python
len(text3)
```
set(): the number of distinct tokens
```python
set(text3)
sorted(set(text(3))
```
count(): how often a word occurs in a text
```python
text3.count('smote')
```
lexical_diversity: len(text) / len(set(text)), dedicate how many times that each word has been used in average
percentage: 100 * text.count('word') / len(text), dedicate the percentage of a word within a text
FreqDist(): frequency distribution for each vocabulary item in the text
```python
fdist1 = FreqDist(text1)
print(fdist1)
fdist1.most_common(50)                                      #List the 5o most frequent words of the text
fdist1['whale']                                             #List how many times that the word 'whale' appears
fdist1.plot(50, cumulative = True)                          #Produce a cumulative frequency graph for the 50 most frequently used words
fdist1.hapaxes()                                            #List the words that occurs only once

sorted(w for w in set(text5) if len(w) > 7 and fdist5[w] > 7) #find the long words that occurs more than one times in the text
```
## Collocation:
A collocation is a sequence of words that occur together usually often. E.g. (red wine)
